{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31715,"status":"ok","timestamp":1645180849297,"user":{"displayName":"Gabriele Ghisleni","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08348063350819652629"},"user_tz":-60},"id":"wesuB-oWcSt-","outputId":"2d0b7afa-b4e0-4030-b11c-f8d2a48b1741"},"outputs":[],"source":["from google.colab import drive\n","from tqdm.auto import tqdm\n","import pprint\n","import torch\n","import os\n","\n","drive.mount('/content/drive')\n","os.chdir(\"drive/MyDrive/____huggingface/__BERTino\")\n","pprint = pprint.PrettyPrinter(indent=4).pprint\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DYpgXRYdcuJP"},"outputs":[],"source":["%%capture\n","# Remember to restart the kernel!\n","!pip install tokenizers\n","!pip install transformers\n","!pip install mlflow"]},{"cell_type":"markdown","metadata":{"id":"7Ryn4EPPZraR"},"source":["# Data pre-processing\n","\n","First of all we have to perform some adjustment on the dataset as it is. We can notice that the labels are encoded in three different columns with their respective probability. Since we are insterted in performing a multi-class classification we have to gather them into one single column.\n","\n","To do this we extract the tree columns in which we are instered *[\"NEG\",\t\"NEU\",\t\"POS\"]*, we transform them into numpy array and lastly we take the index of the maximum for each row."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":112},"executionInfo":{"elapsed":17222,"status":"ok","timestamp":1645181629725,"user":{"displayName":"Gabriele Ghisleni","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08348063350819652629"},"user_tz":-60},"id":"b6sVKg7faikT","outputId":"cc4bf210-1784-44d4-d157-9d88454d1e31"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>NEG</th>\n","      <th>NEU</th>\n","      <th>POS</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>768096868504969216</td>\n","      <td>0.049398</td>\n","      <td>0.861395</td>\n","      <td>0.089207</td>\n","      <td>#Incredible #India #Atulya #Bharat - Land of S...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>768097237620490241</td>\n","      <td>0.028733</td>\n","      <td>0.929554</td>\n","      <td>0.041713</td>\n","      <td>RT @AlwaysTrustKay: Are you near a Western uni...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                   id       NEG       NEU       POS  \\\n","0  768096868504969216  0.049398  0.861395  0.089207   \n","1  768097237620490241  0.028733  0.929554  0.041713   \n","\n","                                                text  \n","0  #Incredible #India #Atulya #Bharat - Land of S...  \n","1  RT @AlwaysTrustKay: Are you near a Western uni...  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","\n","raw_classification = pd.read_csv('data/raw_classification.tsv', sep=\"\\t\")\n","raw_classification.rename(columns={'TWID':'id'}, inplace=True)\n","\n","tweets = pd.read_csv('data/raw_tweets_text.csv')\n","raw_df = pd.merge(raw_classification, tweets, on='id')\n","raw_df.head(2)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1230,"status":"ok","timestamp":1645181630950,"user":{"displayName":"Gabriele Ghisleni","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08348063350819652629"},"user_tz":-60},"id":"DUv-eWQkbBwe","outputId":"f13eb040-7b86-4d5a-a338-3fb7a7349cfd"},"outputs":[{"data":{"text/plain":["(array([[0.04939849, 0.86139469, 0.08920682],\n","        [0.028733  , 0.92955397, 0.04171303],\n","        [0.0065981 , 0.04681042, 0.94659148],\n","        [0.03233298, 0.85094479, 0.11672223],\n","        [0.0080897 , 0.04233099, 0.9495793 ]]),\n"," [1, 1, 2, 1, 2])"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["raw_val = raw_df.loc[:, ['NEG', 'NEU','POS']].values\n","sentiment = torch.argmax(torch.tensor(raw_val), dim=1).tolist()\n","\n","raw_df['sentiment'] = sentiment\n","raw_df.drop(columns=[\"NEG\",\t\"NEU\",\t\"POS\"], inplace=True)\n","\n","# to have an idea of what is going on.\n","raw_val[0:5], sentiment[0:5]"]},{"cell_type":"markdown","metadata":{"id":"gb8HPenWbdXe"},"source":["## Train-Test split\n","\n","Now that we have transformer our three columns into one we are able to split our dataset into a train df and a test df. We do this operation using the *train_test_split* function from sklearn. We also specify to stratify the two datasets so that they will have the same distribution of the target variable in both the sets."]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13965,"status":"ok","timestamp":1645181644912,"user":{"displayName":"Gabriele Ghisleni","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08348063350819652629"},"user_tz":-60},"id":"nMHJ8kTcbUuQ","outputId":"eda21abf-a81f-432a-e0da-74e1daa925ae"},"outputs":[{"name":"stdout","output_type":"stream","text":["train_test_split 943965 235992\n"]}],"source":["from sklearn.model_selection import train_test_split\n","\n","X, sentiment = raw_df.text, raw_df.sentiment\n","X_train, X_test, y_train, y_test = train_test_split(X.values, \n","                                                    sentiment.values, \n","                                                    test_size=.2, \n","                                                    stratify=sentiment.values, \n","                                                    random_state=42)\n","\n","# lastly we save them.\n","train_df = pd.DataFrame({'text': X_train, 'sentiment': y_train})\n","test_df = pd.DataFrame({'text': X_test, 'sentiment': y_test})\n","train_df.to_csv('data/train.csv',index=False, sep=\",\")\n","test_df.to_csv('data/test.csv',index=False, sep=\",\")\n","\n","sent_mapping = {'neg':0, 'neu':1, 'pos':2}\n","print(\"train_test_split\", len(train_df), len(test_df))"]},{"cell_type":"markdown","metadata":{"id":"fQx3erXWcJXn"},"source":["We check the distribution of the target variable in both the datasets."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":439},"executionInfo":{"elapsed":2022,"status":"ok","timestamp":1645181646928,"user":{"displayName":"Gabriele Ghisleni","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08348063350819652629"},"user_tz":-60},"id":"fFL2AeLxkdZb","outputId":"ed1a7f43-1546-4ee1-a5e2-c27dcffe71e1"},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAA4AAAAGmCAYAAAAtXupVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3df7CnV30f9vfHWoQJDkjARoO1cqQZNvUIXPNjR4jSdghKpBU4XtoBKuqJ1kSDpoNw7DQdI9JONQHUwqS1YnVArcbaIhEHoVHs0cYWKDsCxk0bCS2GIATGuhFgrSrQohXCLgUs/Okf98j5anvv3b3S3r27nNdr5jv3eT7nPM85X+4sZ976Pvd8q7sDAADAj7+f2OwJAAAAcHwIgAAAAJMQAAEAACYhAAIAAExCAAQAAJiEAAgAADCJLZs9gWPtRS96UZ999tmbPQ0ANtjnPve5b3f31s2ex8nC+ggwj7XWyB+7AHj22Wdn//79mz0NADZYVX1js+dwMrE+AsxjrTXSI6AAAACTEAABAAAmIQACAABMQgAEAACYhAAIAAAwCQEQAABgEgIgAADAJARAAACASQiAAAAAkxAAAQAAJiEAAgAATEIABAAAmIQACAAAMAkBEAAAYBICIAAAwCSOKgBW1der6t6q+kJV7R+1F1TVvqq6f/w8fdSrqq6tqqWq+mJVvXLhPrtH//uravdC/VXj/kvj2lprDAAAANZvyzr6/s3u/vbC+ZVJ7uzuD1TVleP83UkuTrJ9vF6d5Lokr66qFyS5KsmOJJ3kc1W1t7sfG33ekeTuJLcn2ZnkE2uMASeUs6/8/c2ewqb6+gfeuNlTAOAENfMaaX3kRPRMHgHdleTGcXxjkjct1G/qZXclOa2qXpzkoiT7uvvQCH37kuwcbc/r7ru6u5PcdNi9VhoDAACAdTraANhJ/lVVfa6qLh+1M7r74XH8zSRnjOMzkzy4cO2BUVurfmCF+lpjAAAAsE5H+wjof9zdD1XVX0uyr6r+aLGxu7uq+thP7+jGGKH08iT5mZ/5mY2cBgAAwEnrqD4B7O6Hxs9HkvxukvOSfGs8vpnx85HR/aEkZy1cvm3U1qpvW6GeNcY4fH7Xd/eO7t6xdevWo3lLAAAA0zliAKyq51bVX33yOMmFSb6UZG+SJ3fy3J3ktnG8N8mlYzfQ85M8Ph7jvCPJhVV1+tjN88Ikd4y271bV+WP3z0sPu9dKYwAAALBOR/MI6BlJfnd8M8OWJP+8uz9ZVfckuaWqLkvyjSRvHf1vT/KGJEtJvpfk7UnS3Yeq6n1J7hn93tvdh8bxO5N8JMlzsrz75ydG/QOrjAEAAMA6HTEAdvcDSX5+hfqjSS5Yod5JrljlXnuS7Fmhvj/Jy452DAAAANbvmXwNBAAAACcRARAAAGASAiAAAMAkBEAAAIBJCIAAAACTEAAB4Gmqqj1V9UhVfWmh9k+q6o+q6otV9btVddpC23uqaqmqvlpVFy3Ud47aUlVduVA/p6ruHvWPV9Wpo/7scb402s8+Pu8YgJOdAAgAT99Hkuw8rLYvycu6+z9M8sdJ3pMkVXVukkuSvHRc8+GqOqWqTknyoSQXJzk3ydtG3yT5YJJruvslSR5LctmoX5bksVG/ZvQDgCMSAAHgaeruP0hy6LDav+ruJ8bpXUm2jeNdSW7u7h9099eSLCU5b7yWuvuB7v5hkpuT7KqqSvL6JLeO629M8qaFe904jm9NcsHoDwBrEgABYOP8vSSfGMdnJnlwoe3AqK1Wf2GS7yyEySfrT7nXaH989AeANQmAALABquq/TfJEkt/exDlcXlX7q2r/wYMHN2saAJxABEAAOMaq6peT/EKSX+ruHuWHkpy10G3bqK1WfzTJaVW15bD6U+412p8/+j9Fd1/f3Tu6e8fWrVuPwTsD4GQnAALAMVRVO5P8epJf7O7vLTTtTXLJ2MHznCTbk3w2yT1Jto8dP0/N8kYxe0dw/HSSN4/rdye5beFeu8fxm5N8aiFoAsCqthy5CwCwkqr6WJLXJXlRVR1IclWWd/18dpJ9Y1+Wu7r7v+ru+6rqliRfzvKjoVd094/Gfd6V5I4kpyTZ0933jSHeneTmqnp/ks8nuWHUb0jy0apayvImNJds+JsF4MeCAAgAT1N3v22F8g0r1J7sf3WSq1eo357k9hXqD2R5l9DD699P8pZ1TRYA4hFQAACAaQiAAAAAkxAAAQAAJiEAAgAATEIABAAAmIQACAAAMAkBEAAAYBICIAAAwCQEQAAAgEkIgAAAAJMQAAEAACYhAAIAAExCAAQAAJiEAAgAADAJARAAAGASAiAAAMAkBEAAAIBJCIAAAACTEAABAAAmIQACAABMQgAEAACYhAAIAAAwCQEQAABgEgIgAADAJARAAACASQiAAAAAkxAAAQAAJiEAAgAATEIABAAAmIQACAAAMAkBEAAAYBICIAAAwCQEQAAAgEkIgAAAAJMQAAEAACYhAAIAAExCAAQAAJiEAAgAADAJARAAAGASAiAAAMAkBEAAAIBJCIAAAACTEAABAAAmIQACAABMQgAEAACYhAAIAAAwCQEQAABgEgIgAADAJARAAACASRx1AKyqU6rq81X1e+P8nKq6u6qWqurjVXXqqD97nC+N9rMX7vGeUf9qVV20UN85aktVdeVCfcUxAOBEUFV7quqRqvrSQu0FVbWvqu4fP08f9aqqa8ea9sWqeuXCNbtH//uravdC/VVVde+45tqqqrXGAIAjWc8ngL+a5CsL5x9Mck13vyTJY0kuG/XLkjw26teMfqmqc5NckuSlSXYm+fAIlack+VCSi5Ocm+Rto+9aYwDAieAjWV7TFl2Z5M7u3p7kznGeLK9z28fr8iTXJcthLslVSV6d5LwkVy0EuuuSvGPhup1HGAMA1nRUAbCqtiV5Y5LfGueV5PVJbh1dbkzypnG8a5xntF8w+u9KcnN3/6C7v5ZkKcsL3XlJlrr7ge7+YZKbk+w6whgAsOm6+w+SHDqsvLgOHr4+3tTL7kpyWlW9OMlFSfZ196HufizJviQ7R9vzuvuu7u4kN2Xltdb6CMBRO9pPAP9pkl9P8hfj/IVJvtPdT4zzA0nOHMdnJnkwSUb746P/X9YPu2a1+lpjAMCJ6ozufngcfzPJGeN4vevgmeP48PpaYwDAmo4YAKvqF5I80t2fOw7zeVqq6vKq2l9V+w8ePLjZ0wGAJMn45K43awzrIwCHO5pPAF+b5Ber6utZfjzz9Ul+M8uPrmwZfbYleWgcP5TkrCQZ7c9P8uhi/bBrVqs/usYYT9Hd13f3ju7esXXr1qN4SwCwYb41Ht/M+PnIqK93HXxoHB9eX2uMp7A+AnC4IwbA7n5Pd2/r7rOzvInLp7r7l5J8OsmbR7fdSW4bx3vHeUb7p8Z/ndyb5JKxS+g5Wf5j9s8muSfJ9rHj56ljjL3jmtXGAIAT1eI6ePj6eOnYDfT8JI+PxzjvSHJhVZ0+Nn+5MMkdo+27VXX++Lv4S7PyWmt9BOCobTlyl1W9O8nNVfX+JJ9PcsOo35Dko1W1lOU/jL8kSbr7vqq6JcmXkzyR5Iru/lGSVNW7srwAnpJkT3ffd4QxAGDTVdXHkrwuyYuq6kCWd/P8QJJbquqyJN9I8tbR/fYkb8jyJmjfS/L2JOnuQ1X1viz/B9EkeW93P7mxzDuzvNPoc5J8YryyxhgAsKZ1BcDu/kySz4zjB7K8g+fhfb6f5C2rXH91kqtXqN+e5YXx8PqKYwDAiaC737ZK0wUr9O0kV6xynz1J9qxQ35/kZSvUH11pDAA4kvV8DyAAAAAnMQEQAABgEgIgAADAJARAAACASQiAAAAAkxAAAQAAJiEAAgAATEIABAAAmIQACAAAMAkBEAAAYBICIAAAwCQEQAAAgEkIgAAAAJMQAAEAACYhAAIAAExCAAQAAJiEAAgAADAJARAAAGASAiAAAMAkBEAAAIBJCIAAAACTEAABAAAmIQACAABMQgAEAACYhAAIAAAwCQEQAABgEgIgAADAJARAAACASQiAAAAAkxAAAQAAJiEAAgAATEIABAAAmIQACAAAMAkBEAAAYBICIAAAwCQEQAAAgEkIgAAAAJMQAAEAACYhAAIAAExCAAQAAJiEAAgAADAJARAAAGASAiAAAMAkBEAAAIBJCIAAAACTEAABAAAmIQACAABMQgAEAACYhAAIABugqv5BVd1XVV+qqo9V1U9W1TlVdXdVLVXVx6vq1NH32eN8abSfvXCf94z6V6vqooX6zlFbqqorj/87BOBkJAACwDFWVWcm+ftJdnT3y5KckuSSJB9Mck13vyTJY0kuG5dcluSxUb9m9EtVnTuue2mSnUk+XFWnVNUpST6U5OIk5yZ52+gLAGsSAAFgY2xJ8pyq2pLkryR5OMnrk9w62m9M8qZxvGucZ7RfUFU16jd39w+6+2tJlpKcN15L3f1Ad/8wyc2jLwCsSQAEgGOsux9K8j8l+ZMsB7/Hk3wuyXe6+4nR7UCSM8fxmUkeHNc+Mfq/cLF+2DWr1QFgTQIgABxjVXV6lj+ROyfJTyd5bpYf4Tze87i8qvZX1f6DBw8e7+EBOAEJgABw7P2tJF/r7oPd/edJfifJa5OcNh4JTZJtSR4axw8lOStJRvvzkzy6WD/smtXqT9Hd13f3ju7esXXr1mP13gA4iQmAAHDs/UmS86vqr4y/5bsgyZeTfDrJm0ef3UluG8d7x3lG+6e6u0f9krFL6DlJtif5bJJ7kmwfu4qemuWNYvYeh/cFwEluy5G7AADr0d13V9WtSf4wyRNJPp/k+iS/n+Tmqnr/qN0wLrkhyUerainJoSwHunT3fVV1S5bD4xNJrujuHyVJVb0ryR1Z3mF0T3ffd7zeHwAnLwEQADZAd1+V5KrDyg9keQfPw/t+P8lbVrnP1UmuXqF+e5Lbn/lMAZiJR0ABAAAmIQACAABMQgAEAACYhAAIAAAwCQEQAABgEgIgAADAJI4YAKvqJ6vqs1X1b6vqvqr6x6N+TlXdXVVLVfXx8UW0GV9W+/FRv7uqzl6413tG/atVddFCfeeoLVXVlQv1FccAAABg/Y7mE8AfJHl9d/98kpcn2VlV5yf5YJJruvslSR5Lctnof1mSx0b9mtEvVXVulr/Y9qVJdib5cFWdUlWnJPlQkouTnJvkbaNv1hgDAACAdTpiAOxlfzZOnzVeneT1SW4d9RuTvGkc7xrnGe0XVFWN+s3d/YPu/lqSpSx/Ge55SZa6+4Hu/mGSm5PsGtesNgYAAADrdFR/Azg+qftCkkeS7Evy75J8p7ufGF0OJDlzHJ+Z5MEkGe2PJ3nhYv2wa1arv3CNMQAAAFinowqA3f2j7n55km1Z/sTuZzd0VutUVZdX1f6q2n/w4MHNng4AAMAJaV27gHb3d5J8OslrkpxWVVtG07YkD43jh5KclSSj/flJHl2sH3bNavVH1xjj8Hld3907unvH1q1b1/OWAAAAprHlSB2qamuSP+/u71TVc5L87SxvzvLpJG/O8t/s7U5y27hk7zj/N6P9U93dVbU3yT+vqt9I8tNJtif5bJJKsr2qzslywLskyX85rlltDIATwtlX/v5mT2FTff0Db9zsKQBwgpp5jTyR18cjBsAkL05y49it8yeS3NLdv1dVX05yc1W9P8nnk9ww+t+Q5KNVtZTkUJYDXbr7vqq6JcmXkzyR5Iru/lGSVNW7ktyR5JQke7r7vnGvd68yBgAAAOt0xADY3V9M8ooV6g9k+e8BD69/P8lbVrnX1UmuXqF+e5Lbj3YMAAAA1m9dfwMIAADAyUsABAAAmIQACAAAMAkBEAAAYBICIAAAwCQEQAAAgEkIgAAAAJMQAAEAACYhAAIAAExCAAQAAJiEAAgAADAJARAAAGASAiAAAMAkBEAAAIBJCIAAAACTEAABAAAmIQACAABMQgAEAACYhAAIAAAwCQEQAABgEgIgAADAJARAAACASQiAAAAAkxAAAQAAJiEAAgAATEIABAAAmIQACAAAMAkBEAAAYBICIAAAwCQEQAAAgEkIgAAAAJMQAAEAACYhAAIAAExCAAQAAJiEAAgAG6CqTquqW6vqj6rqK1X1mqp6QVXtq6r7x8/TR9+qqmuraqmqvlhVr1y4z+7R//6q2r1Qf1VV3TuuubaqajPeJwAnFwEQADbGbyb5ZHf/bJKfT/KVJFcmubO7tye5c5wnycVJto/X5UmuS5KqekGSq5K8Osl5Sa56MjSOPu9YuG7ncXhPAJzkBEAAOMaq6vlJ/tMkNyRJd/+wu7+TZFeSG0e3G5O8aRzvSnJTL7sryWlV9eIkFyXZ192HuvuxJPuS7Bxtz+vuu7q7k9y0cC8AWJUACADH3jlJDib536vq81X1W1X13CRndPfDo883k5wxjs9M8uDC9QdGba36gRXqALAmARAAjr0tSV6Z5LrufkWS/yf//nHPJMn45K43chJVdXlV7a+q/QcPHtzIoQA4SQiAAHDsHUhyoLvvHue3ZjkQfms8vpnx85HR/lCSsxau3zZqa9W3rVB/iu6+vrt3dPeOrVu3PuM3BcDJTwAEgGOsu7+Z5MGq+g9G6YIkX06yN8mTO3nuTnLbON6b5NKxG+j5SR4fj4rekeTCqjp9bP5yYZI7Rtt3q+r8sfvnpQv3AoBVbdnsCQDAj6lfSfLbVXVqkgeSvD3L/+H1lqq6LMk3krx19L09yRuSLCX53uib7j5UVe9Lcs/o997uPjSO35nkI0mek+QT4wUAaxIAAWADdPcXkuxYoemCFfp2kitWuc+eJHtWqO9P8rJnOE0AJuMRUAAAgEkIgAAAAJMQAAEAACYhAAIAAExCAAQAAJiEAAgAADAJARAAAGASAiAAAMAkBEAAAIBJCIAAAACTEAABAAAmIQACAABMQgAEAACYhAAIAAAwCQEQAABgEgIgAADAJARAAACASQiAAAAAkxAAAQAAJiEAAgAATOKIAbCqzqqqT1fVl6vqvqr61VF/QVXtq6r7x8/TR72q6tqqWqqqL1bVKxfutXv0v7+qdi/UX1VV945rrq2qWmsMAAAA1u9oPgF8Isk/7O5zk5yf5IqqOjfJlUnu7O7tSe4c50lycZLt43V5kuuS5TCX5Kokr05yXpKrFgLddUnesXDdzlFfbQwAAADW6YgBsLsf7u4/HMd/muQrSc5MsivJjaPbjUneNI53Jbmpl92V5LSqenGSi5Ls6+5D3f1Ykn1Jdo6253X3Xd3dSW467F4rjQEAAMA6retvAKvq7CSvSHJ3kjO6++HR9M0kZ4zjM5M8uHDZgVFbq35ghXrWGAMAAIB1OuoAWFU/leRfJPm17v7uYtv45K6P8dyeYq0xquryqtpfVfsPHjy4kdMAAAA4aR1VAKyqZ2U5/P12d//OKH9rPL6Z8fORUX8oyVkLl28btbXq21aorzXGU3T39d29o7t3bN269WjeEgAAwHSOZhfQSnJDkq90928sNO1N8uROnruT3LZQv3TsBnp+ksfHY5x3JLmwqk4fm79cmOSO0fbdqjp/jHXpYfdaaQwAAADWactR9Hltkr+b5N6q+sKo/aMkH0hyS1VdluQbSd462m5P8oYkS0m+l+TtSdLdh6rqfUnuGf3e292HxvE7k3wkyXOSfGK8ssYYAAAArNMRA2B3/+sktUrzBSv07yRXrHKvPUn2rFDfn+RlK9QfXWkMAAAA1m9du4ACAABw8hIAAQAAJiEAAgAATEIABAAAmIQACAAAMAkBEAAAYBICIAAAwCQEQAAAgEkIgAAAAJMQAAEAACYhAAIAAExCAAQAAJiEAAgAADAJARAAAGASAiAAAMAkBEAAAIBJCIAAAACTEAABAAAmIQACAABMQgAEAACYhAAIABukqk6pqs9X1e+N83Oq6u6qWqqqj1fVqaP+7HG+NNrPXrjHe0b9q1V10UJ956gtVdWVx/u9AXByEgABYOP8apKvLJx/MMk13f2SJI8luWzUL0vy2KhfM/qlqs5NckmSlybZmeTDI1SekuRDSS5Ocm6St42+ALAmARAANkBVbUvyxiS/Nc4ryeuT3Dq63JjkTeN41zjPaL9g9N+V5Obu/kF3fy3JUpLzxmupux/o7h8muXn0BYA1CYAAsDH+aZJfT/IX4/yFSb7T3U+M8wNJzhzHZyZ5MElG++Oj/1/WD7tmtfpTVNXlVbW/qvYfPHjwWLwnAE5yAiAAHGNV9QtJHunuz23mPLr7+u7e0d07tm7duplTAeAEsWWzJwAAP4Zem+QXq+oNSX4yyfOS/GaS06pqy/iUb1uSh0b/h5KcleRAVW1J8vwkjy7Un7R4zWp1AFiVTwAB4Bjr7vd097buPjvLm7h8qrt/Kcmnk7x5dNud5LZxvHecZ7R/qrt71C8Zu4Sek2R7ks8muSfJ9rGr6KljjL3H4a0BcJLzCSAAHD/vTnJzVb0/yeeT3DDqNyT5aFUtJTmU5UCX7r6vqm5J8uUkTyS5ort/lCRV9a4kdyQ5Jcme7r7vuL4TAE5KAiAAbKDu/kySz4zjB7K8g+fhfb6f5C2rXH91kqtXqN+e5PZjOFUAJuARUAAAgEkIgAAAAJMQAAEAACYhAAIAAExCAAQAAJiEAAgAADAJXwNxjJ195e9v9hQ2zdc/8MbNngIAJyjrI8CJwSeAAAAAkxAAAQAAJiEAAgAATEIABAAAmIQACAAAMAkBEAAAYBICIAAAwCQEQAAAgEkIgAAAAJMQAAEAACYhAAIAAExCAAQAAJiEAAgAADAJARAAAGASAiAAAMAkBEAAAIBJCIAAAACTEAABAAAmIQACAABMQgAEAACYhAAIAAAwCQEQAABgEgIgAADAJARAAACASQiAAAAAkxAAAQAAJiEAAgAATOKIAbCq9lTVI1X1pYXaC6pqX1XdP36ePupVVddW1VJVfbGqXrlwze7R//6q2r1Qf1VV3Tuuubaqaq0xAAAAeHqO5hPAjyTZeVjtyiR3dvf2JHeO8yS5OMn28bo8yXXJcphLclWSVyc5L8lVC4HuuiTvWLhu5xHGAAAA4Gk4YgDs7j9Icuiw8q4kN47jG5O8aaF+Uy+7K8lpVfXiJBcl2dfdh7r7sST7kuwcbc/r7ru6u5PcdNi9VhoDAACAp+Hp/g3gGd398Dj+ZpIzxvGZSR5c6Hdg1NaqH1ihvtYY/z9VdXlV7a+q/QcPHnwabwcAAODH3zPeBGZ8ctfHYC5Pe4zuvr67d3T3jq1bt27kVAAAAE5aTzcAfms8vpnx85FRfyjJWQv9to3aWvVtK9TXGgMAAICn4ekGwL1JntzJc3eS2xbql47dQM9P8vh4jPOOJBdW1elj85cLk9wx2r5bVeeP3T8vPexeK40BAADA07DlSB2q6mNJXpfkRVV1IMu7eX4gyS1VdVmSbyR56+h+e5I3JFlK8r0kb0+S7j5UVe9Lcs/o997ufnJjmXdmeafR5yT5xHhljTEAAAB4Go4YALv7bas0XbBC305yxSr32ZNkzwr1/UletkL90ZXGAAAA4Ol5xpvAAAAAcHIQAAEAACYhAAIAAExCAAQAAJiEAAgAADAJARAAjrGqOquqPl1VX66q+6rqV0f9BVW1r6ruHz9PH/WqqmuraqmqvlhVr1y41+7R//6q2r1Qf1VV3TuuuXZ8ny4ArEkABIBj74kk/7C7z01yfpIrqurcJFcmubO7tye5c5wnycVJto/X5UmuS5YDY5a/f/fVSc5LctWToXH0ecfCdTuPw/sC4CQnAALAMdbdD3f3H47jP03ylSRnJtmV5MbR7cYkbxrHu5Lc1MvuSnJaVb04yUVJ9nX3oe5+LMm+JDtH2/O6+67xHbw3LdwLAFYlAALABqqqs5O8IsndSc7o7odH0zeTnDGOz0zy4MJlB0ZtrfqBFeoAsCYBEAA2SFX9VJJ/keTXuvu7i23jk7ve4PEvr6r9VbX/4MGDGzkUACcJARAANkBVPSvL4e+3u/t3Rvlb4/HNjJ+PjPpDSc5auHzbqK1V37ZC/Sm6+/ru3tHdO7Zu3frM3xQAJz0BEACOsbEj5w1JvtLdv7HQtDfJkzt57k5y20L90rEb6PlJHh+Pit6R5MKqOn1s/nJhkjtG23er6vwx1qUL9wKAVW3Z7AkAwI+h1yb5u0nuraovjNo/SvKBJLdU1WVJvpHkraPt9iRvSLKU5HtJ3p4k3X2oqt6X5J7R773dfWgcvzPJR5I8J8knxgsA1iQAAsAx1t3/Oslq38t3wQr9O8kVq9xrT5I9K9T3J3nZM5gmABPyCCgAAMAkBEAAAIBJCIAAAACTEAABAAAmIQACAABMQgAEAACYhAAIAAAwCQEQAABgEgIgAADAJARAAACASQiAAAAAkxAAAQAAJiEAAgAATEIABAAAmIQACAAAMAkBEAAAYBICIAAAwCQEQAAAgEkIgAAAAJMQAAEAACYhAAIAAExCAAQAAJiEAAgAADAJARAAAGASAiAAAMAkBEAAAIBJCIAAAACTEAABAAAmIQACAABMQgAEAACYhAAIAAAwCQEQAABgEgIgAADAJARAAACASQiAAAAAkxAAAQAAJiEAAgAATEIABAAAmIQACAAAMAkBEAAAYBICIAAAwCQEQAAAgEkIgAAAAJMQAAEAACYhAAIAAExCAAQAAJiEAAgAADAJARAAAGASAiAAAMAkTvgAWFU7q+qrVbVUVVdu9nwA4ERhjQRgvU7oAFhVpyT5UJKLk5yb5G1Vde7mzgoANp81EoCn44QOgEnOS7LU3Q909w+T3Jxk1ybPCQBOBNZIANZty2ZP4AjOTPLgwvmBJK8+vFNVXZ7k8nH6Z1X11eMwtxPRi5J8e7MGrw9u1sjE735mM//u//qmjr75jrhGWh+fYtP+rfj/yE3ndz+nmdfHZI018kQPgEelu69Pcv1mz2OzVdX+7t6x2fPg+PO7n5ffPWuxPv57/q3My+9+Tn7vqzvRHwF9KMlZC+fbRg0AZmeNBGDdTvQAeE+S7VV1TlWdmuSSJHs3eU4AcCKwRgKwbif0I6Dd/URVvSvJHUlOSbKnu+/b5GmdyDzmMy+/+3n53U/KGrlu/q3My+9+Tn7vq6ju3uw5AAAAcByc6I+AAgAAcIwIgN6dstMAAARTSURBVAAAAJMQAAEAACZxQm8Cw9qq6meT7MrylwEny9t/7+3ur2zerICNNP7dn5nk7u7+s4X6zu7+5ObNDE4c1keYj/Xx6PkE8CRVVe9OcnOSSvLZ8aokH6uqKzdzbmyeqnr7Zs+BjVNVfz/JbUl+JcmXqmrXQvP/sDmzghOL9ZHVWCN/fFkf18cuoCepqvrjJC/t7j8/rH5qkvu6e/vmzIzNVFV/0t0/s9nzYGNU1b1JXtPdf1ZVZye5NclHu/s3q+rz3f2KTZ0gnACsj6zGGvnjy/q4Ph4BPXn9RZKfTvKNw+ovHm38mKqqL67WlOSM4zkXjrufePKxlu7+elW9LsmtVfXXs/z7B6yPU7NGTsv6uA4C4Mnr15LcWVX3J3lw1H4myUuSvGvTZsXxcEaSi5I8dli9kvxfx386HEffqqqXd/cXkmT8l85fSLInyc9t7tTghGF9nJs1ck7Wx3UQAE9S3f3JqvobSc7LU//I/Z7u/tHmzYzj4PeS/NST/ye3qKo+c/ynw3F0aZInFgvd/USSS6vqf9ucKcGJxfo4PWvknKyP6+BvAAEAACZhF1AAAIBJCIAAAACTEADhJFBVL6+qNyyc/+JGf59VVb2uqv6jjRwDAJ4paySsjwAIJ4eXJ/nLxa2793b3BzZ4zNclsbgBcKKzRsI62AQGNlhVPTfJLUm2JTklyfuSLCX5jSQ/leTbSX65ux8eO5TdneRvJjktyWXjfCnJc7K8k93/OI53dPe7quojSf7fJK9I8teS/L0s74b1miR3d/cvj3lcmOQfJ3l2kn+X5O1jm+SvJ7kxyd9J8qwkb0ny/SR3JflRkoNJfqW7/4+N+N8HgHlZI+H48wkgbLydSf7v7v757n5Zkk8m+V+SvLm7X5Xl76i5eqH/lu4+L8vfZXVVd/8wyX+f5OPd/fLu/vgKY5ye5cXsHyTZm+SaJC9N8nPj0ZgXJfnvkvyt7n5lkv1J/uuF67896tcl+W+6++tJ/tck14wxLWwAbARrJBxnvgcQNt69Sf7nqvpglr+f6LEkL0uyr6qS5f/i+fBC/98ZPz+X5OyjHONfdndX1b1JvtXd9yZJVd037rEtyblJ/s8x5qlJ/s0qY/7n63hvAPBMWCPhOBMAYYN19x9X1Suz/PcJ70/yqST3dfdrVrnkB+Pnj3L0/0afvOYvFo6fPN8y7rWvu992DMcEgGfEGgnHn0dAYYNV1U8n+V53/7Mk/yTJq5NsrarXjPZnVdVLj3CbP03yV5/BNO5K8tqqeskY87lV9Tc2eEwAWJM1Eo4/ARA23s8l+WxVfSHJVVn+W4U3J/lgVf3bJF/IkXcS+3SSc6vqC1X1X6x3At19MMkvJ/lYVX0xy4+2/OwRLvuXSf6zMeZ/st4xAeAoWCPhOLMLKAAAwCR8AggAADAJARAAAGASAiAAAMAkBEAAAIBJCIAAAACTEAABAAAmIQACAABMQgAEAACYxP8HJMMOrh8eobUAAAAASUVORK5CYII=","text/plain":["<Figure size 1080x504 with 2 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","\n","fig,axes= plt.subplots(1,2, figsize=(15,7))\n","train_df.groupby(['sentiment']).size().plot.bar(ax=axes[0])\n","test_df.groupby(['sentiment']).size().plot.bar(ax=axes[1])\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"tBsmL5QQcPSF"},"source":["# DistilBert Model\n","\n","We create now an instance of the DistilBert model. We are performing a classification operation so we can also directly used a DistiBertForSequenceClassification but in this case we preferred create our own torch class and reproduce it following the docs of DistilBert.\n","\n","We inherite the *PreTrainedModel* class from huggingface so that we will be able to save and load the model then in an easier way. We pass the configuration downloaded directly from the huggingface hub.\n","\n","We add the 3 layers, a dense layer with a Relu activation, a dropout and a last dense layer that has an output of 3 as the number of classes that we are trying to predict. The structure is the same as in the docs, as well with the forward method. i just want to point out that:\n","\n","```py\n","distilbert_output = self.distilbert(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)\n","```\n","\n","has the parameter return_dict=False.\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"OCzvo9-ul0HE"},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader\n","from transformers import (AutoModel, AutoTokenizer, PreTrainedModel, PretrainedConfig)\n","from sklearn import metrics\n","from tqdm.auto import tqdm\n","from torch import nn\n","import numpy as np\n","import mlflow\n","import re\n","\n","\n","class DistilBertTweet(PreTrainedModel):\n","    def __init__(self, name='bertino_tweet', dropout=0.2):\n","        super().__init__(config=PretrainedConfig.from_json_file('./model/model_config.json'))\n","        self.name = name\n","\n","        self.distilbert = AutoModel.from_pretrained(\"distilbert-base-uncased\")\n","        self.pre_classifier = nn.Linear(768, 768)\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(dropout)\n","        self.classifier = nn.Linear(768, 3)\n","\n","    def forward(self, input_ids, attention_mask):\n","        distilbert_output = self.distilbert(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)\n","        hidden_state = distilbert_output[0]\n","        pooled_output = hidden_state[:, 0]\n","\n","        pooled_output = self.pre_classifier(pooled_output)\n","        pooled_output = self.relu(pooled_output)\n","        pooled_output = self.dropout(pooled_output)\n","        pooled_output = self.classifier(pooled_output)\n","\n","        return pooled_output"]},{"cell_type":"markdown","metadata":{"id":"tKuctm1Udndh"},"source":["We can have a look at the structure of the model that we are creating:"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["7e5fe96dc20c48439c0745ffcbf24f1a","1ec225fb6d704ac687abd66d1557f523","6390cf2bf9aa462f9acaa9fabc6df648","0a30762950a74837a4c1535fc13fca6e","fbb8cce300534257b137fa086a4f8df7","a9ca76f13b524ea186d69af5def117aa","06fd9f41bc4745f5aaa0ccc62da82ac1","3a3d7dcf416147a9a9d34b893d42f701","e2bfdb1eadd648dbbe0c239ae624f87e","9b82349c2b6a49e3b41b6b6074d653c3","985cff67b592480999fbea3135f167a6","822e183b78ab440ea841a3e411bc7320","5afc06c80d1242319d703458cfa04406","56eff2be97174399a585a9f2af71842b","1d0dca45c364424ab6c62a6e5484a4da","acc3a1451fee4741bb6900971e4cc8e3","420faf7240a7407aa05b286e04ea7594","9abcfe66a7e740e3bc5ac9bd4051aa12","66ac5565617845c0a86cfb9ab9b20b47","13e852e28e3a42ea9d3a8d0900e5e197","720b5536371a4828a05815244641dfec","f0be0a3d322b49f38f83afa719f6568b"]},"executionInfo":{"elapsed":21281,"status":"ok","timestamp":1645181669567,"user":{"displayName":"Gabriele Ghisleni","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08348063350819652629"},"user_tz":-60},"id":"5jIvR9LldmhR","outputId":"1647b3f5-4d4d-46ab-a253-7d7964dc2d18"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.weight']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"data":{"text/plain":["DistilBertTweet(\n","  (distilbert): DistilBertModel(\n","    (embeddings): Embeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (transformer): Transformer(\n","      (layer): ModuleList(\n","        (0): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (1): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (2): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (3): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (4): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (5): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n","  (relu): ReLU()\n","  (dropout): Dropout(p=0.2, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",")"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["DistilBertTweet()"]},{"cell_type":"markdown","metadata":{"id":"7TaG7MA2d2Ly"},"source":["# Torch Dataset and DataLoader\n","\n","We create now our actual dataset and dataloader using the torch classes.\n","we recall that torch class Dataset stores the samples and their corresponding labels, while DataLoader wraps an iterable around the Dataset to enable easy access to the samples.\n","\n","each dataset must have the __len__ properties and the __getitem__ properties well defined. in our case we decide to tokenize the sentence while are feeded to the model. Doing this basically when we iterate over the dataset the elements will be first cleaned up and then tokenized.\n","\n","We used some regex to clean up such as removing all the words that starts with @ (for instance the tag as @myself), removed all the words starting with http and others. \n","\n","then we create the tokens as follow:\n","\n","```py\n","        inputs = self._tokenizer.encode_plus(\n","            comment_text,\n","            # None,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            truncation=True,\n","            return_token_type_ids=False,\n","        )\n","```\n","\n","Where max_length we remember that for BERT and similar must be less than 512, the return_token_type_ids in our case is useless since it represent the number of the sentece (BERT was trained also to understand if two sentences could be attacched, in that case the first sentece had token_type_ids = 0 while the second = 1, since we are not reproducing this kind of training we just remove it). We allow truncation so in case there are some sentences that have more that max_length tokens they will be truncated and we specify the padding techniques, in this case to the maximum_length.\n","\n","We also create a simple function that create the dataset and the dataloader according to the batch_size argument passed. "]},{"cell_type":"code","execution_count":11,"metadata":{"id":"SO5fx-9NdgaG"},"outputs":[],"source":["class CustomDataset(Dataset):\n","    sent_mapping = {'neg':0, 'neu':1, 'pos':2}\n","    def __init__(self, dataframe, tokenizer, max_len=140):\n","        self._tokenizer = tokenizer\n","        self.text = dataframe.text\n","        self.targets = dataframe.sentiment\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.targets)\n","\n","    @property\n","    def tokenizer(self):\n","      return self._tokenizer\n","\n","    @property\n","    def get_labels(self):\n","      return self.labels\n","\n","    def pre_process_text(self,row):\n","      row = re.sub(r'@\\S+|http\\S*|\\!|\\?|#|RT+|\\d+|\\.*|\\,*|\\-*|@|\\[|\\]|\\(|\\)|\\:|\\;|\\+|\\*|\\-|\\_|\\\"', '', row).strip()\n","      row = row.lower()\n","      return row\n","\n","    def __getitem__(self, index):\n","        comment_text = self.text[index]\n","        comment_text = self.pre_process_text(comment_text)\n","        \n","        inputs = self._tokenizer.encode_plus(\n","            comment_text,\n","            # None,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            truncation=True,\n","            return_token_type_ids=False,\n","        )\n","\n","        ids = inputs['input_ids']\n","        mask = inputs['attention_mask']\n","\n","        return ({\n","                'ids': torch.tensor(ids, dtype=torch.long),\n","                'mask': torch.tensor(mask, dtype=torch.long),\n","                'targets': torch.tensor(self.targets[index], dtype=torch.float)\n","                })\n","      \n","\n","\n","def create_dataset(train_raw, test_raw, tokenizer, tokenizer_lenght, BATCH_SIZE):\n","  training_set = CustomDataset(train_raw, tokenizer, tokenizer_lenght)\n","  eval_set = CustomDataset(test_raw, tokenizer, tokenizer_lenght)\n","  return (DataLoader(training_set, batch_size= BATCH_SIZE, shuffle=True), DataLoader(eval_set, batch_size= BATCH_SIZE, shuffle=True))"]},{"cell_type":"markdown","metadata":{"id":"njoWNeqzgBBG"},"source":["we can test it out to understand how it behave"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3768,"status":"ok","timestamp":1645182384108,"user":{"displayName":"Gabriele Ghisleni","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08348063350819652629"},"user_tz":-60},"id":"RD0qjlAlfvF2","outputId":"b0b64f9c-2751-45dd-b547-a68cc3c5dde8"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: 100%|██████████| 28.0/28.0 [00:00<00:00, 9.32kB/s]\n","Downloading: 100%|██████████| 226k/226k [00:00<00:00, 621kB/s] \n","Downloading: 100%|██████████| 455k/455k [00:00<00:00, 713kB/s] \n"]},{"name":"stdout","output_type":"stream","text":["tensor([[  101, 28939,  2106,  1057,  2298,  1999, 24471,  5789,  4524,   102],\n","        [  101,  3696,  2039,  2000,  6951,  2012, 23217,  2414,  2024,   102],\n","        [  101,  4086,  1055,  3630,  6559,  8301,  4246, 15509,  5645,   102],\n","        [  101,  2023,  2003,  1037,  9984,  1005,  1055,  3145,  3614,   102],\n","        [  101,   100,  2021,  1045,  2123,  1005,  1056,  2031,  2026,   102],\n","        [  101,  4742,  5485,  2128, 15532,  1999,  8586,  4487, 24137,   102],\n","        [  101,  3422, 11690,  3185, 23601,  2063,  2007, 11660,  4147,   102],\n","        [  101,  2572,  9541,  2953,  2003,  2085,  2206,  2033,  2006,   102]]) [CLS] bf did u look in ur makeup bag [SEP]\n"]}],"source":["tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\", use_fast=True)\n","train, test = create_dataset(train_df, test_df, tokenizer, 10, 8)\n","\n","for idx, val in enumerate(train):\n","  print(val['ids'], tokenizer.decode(val['ids'][0]))\n","  break"]},{"cell_type":"markdown","metadata":{"id":"82Vl2UJOg4u6"},"source":["# Trainer\n","\n","Now we create our trainer class wich will handle the training process of our model. We largely used MLFLOW to log our parameters and metrics. MLFLOW is a free open-source platform that allow to handle end-end machine learning experiments. \n","\n","this is an example of metrics tracking provided freely by mlflow and databricks"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"GEwQ-EGNvOsu"},"outputs":[],"source":["from sklearn.metrics import classification_report, accuracy_score\n","\n","class Trainer:\n","  def __init__(self, model, loss_fn, epoch, path, optimizer, scheduler):\n","    self.model = model\n","    self.loss_fn = loss_fn\n","    self.epochs = epoch \n","    self.optimizer = optimizer\n","    self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') \n","    self.scheduler = scheduler\n","    self.path = path\n","\n","  def training_loop(self, training_loader, testing_loader, run_name, **kwargs):\n","    self.model.to(self.device)\n","    with mlflow.start_run(run_name=run_name) as run:  \n","      for key, value in kwargs.items():\n","        mlflow.log_param(key, value)\n","      self.train(training_loader, testing_loader)\n","      mlflow.pytorch.log_model(self.model, self.model.name)\n","\n","  def handle_metrics_multiclass(self, metrics, output, truth):\n","    accuracy = accuracy_score(output.cpu(), truth.cpu())\n","    batch_metric = classification_report(output.cpu(), truth.cpu(), \n","                                         target_names=['neg','neu','pos'],\n","                                         labels=[0, 1, 2], \n","                                         output_dict=True, zero_division=0)\n","    metrics['accuracy'] += accuracy\n","    metrics['macro avg'][\"f1-score\"] += batch_metric['macro avg'][\"f1-score\"]\n","    metrics['macro avg'][\"precision\"] += batch_metric['macro avg'][\"precision\"]\n","    metrics['neg'][\"precision\"] += batch_metric['neg'][\"precision\"]\n","    metrics['neg'][\"f1-score\"] += batch_metric['neg'][\"f1-score\"]\n","    metrics['neg'][\"recall\"] += batch_metric['neg'][\"recall\"]\n","    metrics['neu'][\"precision\"] += batch_metric['neu'][\"precision\"]\n","    metrics['neu'][\"f1-score\"] += batch_metric['neu'][\"f1-score\"]\n","    metrics['neu'][\"recall\"] += batch_metric['neu'][\"recall\"]\n","    metrics['pos'][\"precision\"] += batch_metric['pos'][\"precision\"]\n","    metrics['pos'][\"f1-score\"] += batch_metric['pos'][\"f1-score\"]\n","    metrics['pos'][\"recall\"] += batch_metric['pos'][\"recall\"]\n","\n","    metrics['step'] += 1\n","\n","  \n","  def log_multiple_metrics(self, metrics, step, prefix='train'):\n","      for key, value in metrics.items():\n","        if key != 'step':\n","          if type(value) == dict:\n","            for key_inside, value_inside in metrics[key].items():\n","              mlflow.log_metric(f\"{prefix}_{key}_{key_inside}\", (value_inside/metrics['step']), step=step)\n","          elif key == 'loss':\n","           mlflow.log_metric(f\"{prefix}_{key}\", (value), step=step)\n","          else:\n","           mlflow.log_metric(f\"{prefix}_{key}\", (value/metrics['step']), step=step)\n","\n","      \n","  def train(self, training_loader, testing_loader):\n","        step = 0\n","        for epoch in (range(self.epochs)):\n","          self.model.train()\n","\n","          metrics_train = {\n","              \"step\":0, \"accuracy\":0, \n","              \"macro avg\": {\"f1-score\":0, \"precision\":0},\n","              \"neg\": {'f1-score': 0.0, 'precision': 0.0, 'recall': 0.0},\n","              \"neu\": {'f1-score': 0.0, 'precision': 0.0, 'recall': 0.0},\n","              \"pos\": {'f1-score': 0.0, 'precision': 0.0, 'recall': 0.0}}\n","\n","          total, correct = 0,0\n","          for idx, data in tqdm(enumerate(training_loader), total=len(training_loader)):\n","              ids = data['ids'].to(self.device, dtype = torch.long)\n","              mask = data['mask'].to(self.device, dtype = torch.long)\n","              targets = data['targets'].to(self.device, dtype = torch.long)\n","\n","              outputs = self.model(ids, mask) \n","              self.optimizer.zero_grad()\n","              loss = self.loss_fn(outputs, targets)\n","\n","              _, predicted = torch.max(outputs.data, 1)\n","              total += targets.size(0)\n","              correct += (predicted == targets).sum().item()\n","\n","              self.handle_metrics_multiclass(metrics_train, predicted, targets)\n","\n","              if idx%1000 == 0:\n","                  metrics_train['loss'] = loss.item()\n","                  self.log_multiple_metrics(metrics_train, step=step, prefix='train')\n","                  step += 1\n","\n","              if idx % 20_000 == 0 and idx != 0:\n","                self.scheduler.step()\n","\n","              self.optimizer.zero_grad()\n","              loss.backward()\n","              self.optimizer.step()\n","\n","          train_accuracy = correct/total\n","          mlflow.log_metric(\"train accuracy__\",train_accuracy, step=epoch)\n","\n","          self.log_multiple_metrics(metrics_train, step=step, prefix='train')\n","          self.validation(testing_loader, epoch)\n","        \n","\n","  def validation(self, testing_loader, epoch):\n","    self.model.eval()\n","\n","    metrics_test = {\n","    \"step\":0, \"accuracy\":0, \n","    \"macro avg\": {\"f1-score\":0, \"precision\":0},\n","    \"neg\": {'f1-score': 0.0, 'precision': 0.0, 'recall': 0.0},\n","    \"neu\": {'f1-score': 0.0, 'precision': 0.0, 'recall': 0.0},\n","    \"pos\": {'f1-score': 0.0, 'precision': 0.0, 'recall': 0.0}}\n","    \n","    total, correct = 0,0\n","    with torch.no_grad():\n","        for idx, data in tqdm(enumerate(testing_loader), total=len(testing_loader)):\n","            ids = data['ids'].to(self.device, dtype = torch.long)\n","            mask = data['mask'].to(self.device, dtype = torch.long)\n","            targets = data['targets'].to(self.device, dtype = torch.long)\n","\n","            outputs = self.model(ids, mask) \n","\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += targets.size(0)\n","            correct += (predicted == targets).sum().item()  \n","\n","            self.handle_metrics_multiclass(metrics_test, predicted, targets)\n","\n","    mlflow.log_metric(\"test accuracy__\", correct/total, step=epoch)\n","\n","    self.log_multiple_metrics(metrics_test, step=epoch, prefix='test')\n","\n","    torch.save(self.model, f\"{self.path}{self.model.name}.pt\")\n","\n","    torch.save({\"optimizer\": self.optimizer.state_dict(), \n","                \"scheduler\": self.scheduler.state_dict(), \"epoch\": epoch}, \n","                f\"{self.path}{self.model.name}-re_train_args.pt\")\n","\n","def print_details(model, params):\n","    print(\"-\"*150)\n","    print(model)\n","    print(\"-\"*150)\n","    for layer in params['trainable_layers']:\n","      print(f\"Layer to train --> {layer}\")\n","    print(\"-\"*150)\n","    pprint(params)\n","    print(\"-\"*150)"]},{"cell_type":"markdown","metadata":{"id":"50bNas7biOQm"},"source":["# Wrap Up\n","Now we bring all together and we can train the model.\n","\n","If you want to keep track of the experiment online you can register to [databricks community](https://docs.databricks.com/applications/mlflow/tracking.html) edition and pass your credentials. otherwhise you can just comment those lines. \n","\n","Before training the Model we freeze all the layers that come directly from the encoder. We want to train only the last classification layer. we perform this operation by setting *requires_grad* equal to false for all the layer that cointains 'bert' inside the name. "]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":208,"referenced_widgets":["a0b5e3259d7a4de08adf2e05309f7475","d11940bf36564be3b655adaaa90290f8","b8d6440a3d494d46be46c324c2a3317b","d9fd7cf0b0ea45d4a5f2a197907ccc3f","d39de3a3fa8a4f70b0abf71d43fde1b0","8dc7d611756541ffaef3cb769bd97cfb","c10f21138c3f4256b2ae5f241216295b","195d01f719334471813f6d853fe52f11","66a402e44748451a9ef7b17176ca02cb","1d837c5638f14e17979481aa4500ccfc","e0a154a58a4d48ca9fdff9766ac6981a"]},"id":"ZtD5QU-3vagp","outputId":"817d9953-7957-46a5-d6ac-02e967991270"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.weight']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["------------------------------------------------------------------------------------------------------------------------------------------------------\n","DistilBertTweet(\n","  (distilbert): DistilBertModel(\n","    (embeddings): Embeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (transformer): Transformer(\n","      (layer): ModuleList(\n","        (0): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (1): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (2): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (3): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (4): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (5): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n","  (relu): ReLU()\n","  (dropout): Dropout(p=0.2, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",")\n","------------------------------------------------------------------------------------------------------------------------------------------------------\n","Layer to train --> pre_classifier.weight\n","Layer to train --> pre_classifier.bias\n","Layer to train --> classifier.weight\n","Layer to train --> classifier.bias\n","------------------------------------------------------------------------------------------------------------------------------------------------------\n","{   'batch_size': 16,\n","    'epochs': 4,\n","    'gamma': 0.96,\n","    'lr': 0.0001,\n","    'model_name': 'eng_distilber',\n","    'tokenizer_max_lenght': 25,\n","    'train-test': (943965, 235992),\n","    'trainable_layers': [   'pre_classifier.weight',\n","                            'pre_classifier.bias',\n","                            'classifier.weight',\n","                            'classifier.bias']}\n","------------------------------------------------------------------------------------------------------------------------------------------------------\n"]}],"source":["train = True\n","\n","if train:\n","  !databricks configure --host https://community.cloud.databricks.com/\n","  mlflow.set_tracking_uri('databricks')\n","  mlflow.set_experiment(\"/Users/gabriele.ghisleni01@gmail.com/Bertino_Tweets\")\n","\n","  PARAMS = {\"epochs\":4, \"lr\":1e-04, \"batch_size\":16, \"model_name\": 'eng_distilber', 'gamma':0.96,\n","            \"tokenizer_max_lenght\":25, 'trainable_layers':[], \"train-test\": (len(train_df), len(test_df))}\n","\n","  tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\", use_fast=True)\n","  training_loader, testing_loader = create_dataset(train_df, test_df, tokenizer, PARAMS['tokenizer_max_lenght'], PARAMS['batch_size'])\n","\n","  model = DistilBertTweet(name=PARAMS['model_name'])\n","  loss_fn = torch.nn.CrossEntropyLoss()\n","  optimizer = torch.optim.Adam(params=model.parameters(), lr=PARAMS['lr'])\n","  scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=PARAMS['gamma'])\n","\n","  # model = torch.load('./model/bert_simple.pt')\n","  # optimizer.load_state_dict(torch.load('./model/bert_simple-optimizer.pt'))\n","  \n","  for name, param in model.named_parameters():\n","    if \"bert\" in name: param.requires_grad = False\n","    if param.requires_grad:\n","      PARAMS['trainable_layers'].append(name)\n","  \n","  print_details(model, PARAMS)\n","  trainer = Trainer(model=model, loss_fn=loss_fn, optimizer=optimizer, scheduler=scheduler, epoch=PARAMS['epochs'],  path='./model/')\n","  trainer.training_loop(training_loader, testing_loader, run_name=PARAMS['model_name'], **PARAMS)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"SentimentAnalysis-DistilBERT.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"06fd9f41bc4745f5aaa0ccc62da82ac1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a30762950a74837a4c1535fc13fca6e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2bfdb1eadd648dbbe0c239ae624f87e","max":483,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3a3d7dcf416147a9a9d34b893d42f701","value":483}},"13e852e28e3a42ea9d3a8d0900e5e197":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"195d01f719334471813f6d853fe52f11":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1d0dca45c364424ab6c62a6e5484a4da":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_13e852e28e3a42ea9d3a8d0900e5e197","max":267967963,"min":0,"orientation":"horizontal","style":"IPY_MODEL_66ac5565617845c0a86cfb9ab9b20b47","value":267967963}},"1d837c5638f14e17979481aa4500ccfc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ec225fb6d704ac687abd66d1557f523":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a3d7dcf416147a9a9d34b893d42f701":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"420faf7240a7407aa05b286e04ea7594":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"56eff2be97174399a585a9f2af71842b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9abcfe66a7e740e3bc5ac9bd4051aa12","placeholder":"​","style":"IPY_MODEL_420faf7240a7407aa05b286e04ea7594","value":"Downloading: 100%"}},"5afc06c80d1242319d703458cfa04406":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6390cf2bf9aa462f9acaa9fabc6df648":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_06fd9f41bc4745f5aaa0ccc62da82ac1","placeholder":"​","style":"IPY_MODEL_a9ca76f13b524ea186d69af5def117aa","value":"Downloading: 100%"}},"66a402e44748451a9ef7b17176ca02cb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66ac5565617845c0a86cfb9ab9b20b47":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"720b5536371a4828a05815244641dfec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7e5fe96dc20c48439c0745ffcbf24f1a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6390cf2bf9aa462f9acaa9fabc6df648","IPY_MODEL_0a30762950a74837a4c1535fc13fca6e","IPY_MODEL_fbb8cce300534257b137fa086a4f8df7"],"layout":"IPY_MODEL_1ec225fb6d704ac687abd66d1557f523"}},"822e183b78ab440ea841a3e411bc7320":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_56eff2be97174399a585a9f2af71842b","IPY_MODEL_1d0dca45c364424ab6c62a6e5484a4da","IPY_MODEL_acc3a1451fee4741bb6900971e4cc8e3"],"layout":"IPY_MODEL_5afc06c80d1242319d703458cfa04406"}},"8dc7d611756541ffaef3cb769bd97cfb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"985cff67b592480999fbea3135f167a6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9abcfe66a7e740e3bc5ac9bd4051aa12":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b82349c2b6a49e3b41b6b6074d653c3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a0b5e3259d7a4de08adf2e05309f7475":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b8d6440a3d494d46be46c324c2a3317b","IPY_MODEL_d9fd7cf0b0ea45d4a5f2a197907ccc3f","IPY_MODEL_d39de3a3fa8a4f70b0abf71d43fde1b0"],"layout":"IPY_MODEL_d11940bf36564be3b655adaaa90290f8"}},"a9ca76f13b524ea186d69af5def117aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"acc3a1451fee4741bb6900971e4cc8e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0be0a3d322b49f38f83afa719f6568b","placeholder":"​","style":"IPY_MODEL_720b5536371a4828a05815244641dfec","value":" 256M/256M [00:18&lt;00:00, 34.1MB/s]"}},"b8d6440a3d494d46be46c324c2a3317b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c10f21138c3f4256b2ae5f241216295b","placeholder":"​","style":"IPY_MODEL_8dc7d611756541ffaef3cb769bd97cfb","value":"  5%"}},"c10f21138c3f4256b2ae5f241216295b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d11940bf36564be3b655adaaa90290f8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d39de3a3fa8a4f70b0abf71d43fde1b0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0a154a58a4d48ca9fdff9766ac6981a","placeholder":"​","style":"IPY_MODEL_1d837c5638f14e17979481aa4500ccfc","value":" 2943/58998 [02:48&lt;43:11, 21.63it/s]"}},"d9fd7cf0b0ea45d4a5f2a197907ccc3f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_66a402e44748451a9ef7b17176ca02cb","max":58998,"min":0,"orientation":"horizontal","style":"IPY_MODEL_195d01f719334471813f6d853fe52f11","value":2943}},"e0a154a58a4d48ca9fdff9766ac6981a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2bfdb1eadd648dbbe0c239ae624f87e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0be0a3d322b49f38f83afa719f6568b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fbb8cce300534257b137fa086a4f8df7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_985cff67b592480999fbea3135f167a6","placeholder":"​","style":"IPY_MODEL_9b82349c2b6a49e3b41b6b6074d653c3","value":" 483/483 [00:00&lt;00:00, 2.24kB/s]"}}}}},"nbformat":4,"nbformat_minor":0}
